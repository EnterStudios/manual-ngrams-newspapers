{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%% libraries\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "# run for jupyter notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_stitcher(ybegin, yend,\n",
    "                  months = ['{num:02d}'.format(num=x) for x in range(1, 13)], \n",
    "                  days= ['{num:02d}'.format(num=x) for x in range(1, 32)] ):\n",
    "    years = [str(x) for x in range(ybegin, yend)]\n",
    "    filelist = []\n",
    "    combinations = list(itertools.product(years, months, days))\n",
    "    for combination in combinations:\n",
    "        arguments = \"_\".join(combination)\n",
    "        command = 'wfreqs_TKP_' + arguments + '.csv'\n",
    "        filelist.append(command)\n",
    "    return filelist\n",
    "\n",
    "\n",
    "def kw_search(flist, keywords, inpdir,fuzzymatch=False,verbose=False):\n",
    "    freqcols = ['word', 'freq']\n",
    "    # initialise dataframe\n",
    "    tallies = pd.DataFrame(flist, columns=['file']).set_index('file')\n",
    "    tallies['exists']=np.nan\n",
    "    tallies['wordcount']=np.nan\n",
    "    for kw in keywords:\n",
    "        tallies[kw] = np.nan\n",
    "    # count in all files\n",
    "    for infile in flist:\n",
    "        file = inpdir + '/' + infile\n",
    "        exist_flag = os.path.exists(file)\n",
    "        if exist_flag:\n",
    "            tallies.at[infile, 'exists'] = 1\n",
    "            tkp = pd.read_csv(file, usecols=freqcols, index_col='word')\n",
    "            tallies.at[infile, 'wordcount'] = tkp.freq.sum()\n",
    "            for kw in keywords:\n",
    "                try:\n",
    "                    # fuzzy match \n",
    "                    if fuzzymatch:\n",
    "                        tkp['word'] = tkp.index\n",
    "                        tallies.at[infile, kw] = tkp[tkp['word'].str.contains(kw)]['freq'].sum()\n",
    "                    else:\n",
    "                    # strict match\n",
    "                        tallies.at[infile, kw] = pd.to_numeric(tkp.loc[kw])[0]\n",
    "                    \n",
    "                except:\n",
    "                    continue\n",
    "            if verbose: print(infile, 'loaded and searched')\n",
    "            del tkp\n",
    "        else:\n",
    "            tallies.at[infile, 'exists'] = 0\n",
    "            if verbose: print(infile, ' does not exist')\n",
    "            continue\n",
    "    # subset to nonempty rows\n",
    "    data = tallies[(tallies['exists']==1)]\n",
    "    return(data)\n",
    "\n",
    "def prep_ngram_data(flist,keywords,inp,fuzzymatch=False,percent=False):\n",
    "    data = kw_search(flist, keywords, inp, fuzzymatch)\n",
    "    # this will print a barrage of warnings \n",
    "    data.reset_index(level=0, inplace=True)\n",
    "    data.file = data.file.str[11:21] # hacky - relies on particular naming format\n",
    "    data['date']=pd.to_datetime(data['file'], format='%Y_%m_%d')\n",
    "    keepvars = ['date','wordcount']+keywords\n",
    "    \n",
    "    # normalize by day word-count \n",
    "    if percent:\n",
    "        for k in keywords:\n",
    "            data[k] = (data[k]/data['wordcount'])*100\n",
    "        \n",
    "    clean = data[keepvars].set_index('date')\n",
    "    \n",
    "    return(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prep_ngram_data` optionally applies normalisation on word-counts to construct\n",
    "$$\n",
    "P_{w,t} = \\frac{N_{w,t}}{\\sum_{i}^I N_{i,t}}\n",
    "$$\n",
    "\n",
    "for word $w$ on day $t$, where the denominator is the word count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interactive plot (uses plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactive(df,vars,header='Appearances in TKP archive'):\n",
    "    data = []\n",
    "    for v in vars:\n",
    "        data.append(go.Scatter(x = df.index,y = df[v],name=v))\n",
    "    \n",
    "    layout = dict(\n",
    "        title=header,\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1,label='1m',step='month',stepmode='backward'),\n",
    "                    dict(count=6,label='6m',step='month',stepmode='backward'),\n",
    "                    dict(count=1,label='YTD',step='year',stepmode='todate'),\n",
    "                    dict(count=1,label='1y',step='year',stepmode='backward'),\n",
    "                    dict(count=2,label='2y',step='year',stepmode='backward'),\n",
    "                    dict(step='all')\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(),\n",
    "            type='date'\n",
    "        )\n",
    "    )\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    return py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preliminaries\n",
    "working = '/media/alal/NEPALINEWS/The Kathmandu Post'\n",
    "os.chdir(working)\n",
    "tmp = '/home/alal/tmp'\n",
    "inp = '/media/alal/NEPALINEWS/The Kathmandu Post/word_frequencies'\n",
    "\n",
    "# set up list for date ranges\n",
    "flist = date_stitcher(2007, 2018)\n",
    "keywords = ['language', 'bhasa', 'maithili','newar', 'tharu', 'tamang']\n",
    "langs_nep = ['maithili', 'bhojpuri', 'tharu', 'tamang', 'newar', 'bajjika',\n",
    "             'magar','dotyali', 'urdu', 'awadhi', 'limbu', 'gurung', 'baitadeli', 'rai', 'aachami']\n",
    "disasters = ['earthquake', 'fire', 'flood','drought','landslide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 1e+03 ms, total: 1min 51s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean = prep_ngram_data(flist,keywords,inp,fuzzymatch=True,percent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordcount</th>\n",
       "      <th>language</th>\n",
       "      <th>bhasa</th>\n",
       "      <th>maithili</th>\n",
       "      <th>newar</th>\n",
       "      <th>tharu</th>\n",
       "      <th>tamang</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-03-27</th>\n",
       "      <td>16336.0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-28</th>\n",
       "      <td>15718.0</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-29</th>\n",
       "      <td>16547.0</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-30</th>\n",
       "      <td>15374.0</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-31</th>\n",
       "      <td>14247.0</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wordcount  language  bhasa  maithili     newar     tharu    tamang\n",
       "date                                                                          \n",
       "2007-03-27    16336.0  0.000122    0.0       0.0  0.000000  0.000000  0.000000\n",
       "2007-03-28    15718.0  0.000254    0.0       0.0  0.000127  0.000127  0.000127\n",
       "2007-03-29    16547.0  0.000121    0.0       0.0  0.000060  0.000000  0.000000\n",
       "2007-03-30    15374.0  0.000260    0.0       0.0  0.000065  0.000000  0.000000\n",
       "2007-03-31    14247.0  0.000070    0.0       0.0  0.000070  0.000000  0.000070"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 14s, sys: 620 ms, total: 4min 15s\n",
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "langs = prep_ngram_data(flist,langs_nep,inp,fuzzymatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 544 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stressors = prep_ngram_data(flist,disasters,inp,fuzzymatch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that daily word-counts don't bounce around too much over time - that would mean trends in raw counts are misleading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~apoorvalal/65.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_interactive(clean,['wordcount'],header='word count TKP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~apoorvalal/67.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_interactive(clean,keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draw time for this plot will be slow for clients without much RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alal/anaconda3/lib/python3.6/site-packages/plotly/api/v1/clientresp.py:40: UserWarning:\n",
      "\n",
      "Estimated Draw Time Slow\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~apoorvalal/69.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_interactive(langs,langs_nep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~apoorvalal/71.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_interactive(stressors,disasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
