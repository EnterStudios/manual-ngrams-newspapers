{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%% libraries\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "# run for jupyter notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_stitcher(prefix,ybegin, yend,\n",
    "                  months = ['{num:02d}'.format(num=x) for x in range(1, 13)], \n",
    "                  days= ['{num:02d}'.format(num=x) for x in range(1, 32)] ):\n",
    "    years = [str(x) for x in range(ybegin, yend)]\n",
    "    filelist = []\n",
    "    combinations = list(itertools.product(years, months, days))\n",
    "    for combination in combinations:\n",
    "        arguments = \"_\".join(combination)\n",
    "        command = prefix + arguments + '.csv'\n",
    "        filelist.append(command)\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kw_search(flist, keywords, inpdir,fuzzymatch=False,verbose=False):\n",
    "    freqcols = ['word', 'freq']\n",
    "    # initialise dataframe\n",
    "    tallies = pd.DataFrame(flist, columns=['file']).set_index('file')\n",
    "    tallies['exists']=np.nan\n",
    "    tallies['wordcount']=np.nan\n",
    "    for kw in keywords:\n",
    "        tallies[kw] = np.nan\n",
    "    # count in all files\n",
    "    for infile in flist:\n",
    "        file = inpdir + '/' + infile\n",
    "        exist_flag = os.path.exists(file)\n",
    "        if exist_flag:\n",
    "            tallies.at[infile, 'exists'] = 1\n",
    "            tkp = pd.read_csv(file, usecols=freqcols, index_col='word')\n",
    "            tallies.at[infile, 'wordcount'] = tkp.freq.sum()\n",
    "            for kw in keywords:\n",
    "                try:\n",
    "                    # fuzzy match \n",
    "                    if fuzzymatch:\n",
    "                        tkp['word'] = tkp.index\n",
    "                        tallies.at[infile, kw] = tkp[tkp['word'].str.contains(kw)]['freq'].sum()\n",
    "                    else:\n",
    "                    # strict match\n",
    "                        tallies.at[infile, kw] = pd.to_numeric(tkp.loc[kw])[0]\n",
    "                    \n",
    "                except:\n",
    "                    continue\n",
    "            if verbose: print(infile, 'loaded and searched')\n",
    "            del tkp\n",
    "        else:\n",
    "            tallies.at[infile, 'exists'] = 0\n",
    "            if verbose: print(infile, ' does not exist')\n",
    "            continue\n",
    "    # subset to nonempty rows\n",
    "    data = tallies[(tallies['exists']==1)]\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_ngram_data(flist,keywords,inp,fuzzymatch=False,percent=False):\n",
    "    data = kw_search(flist, keywords, inp, fuzzymatch)\n",
    "    # this will print a barrage of warnings \n",
    "    data.reset_index(level=0, inplace=True)\n",
    "    data.file = data.file.str[11:21] # hacky - relies on particular naming format\n",
    "    data['date']=pd.to_datetime(data['file'], format='%Y_%m_%d')\n",
    "    keepvars = ['date','wordcount']+keywords\n",
    "    \n",
    "    # normalize by day word-count \n",
    "    if percent:\n",
    "        for k in keywords:\n",
    "            data[k] = (data[k]/data['wordcount'])*100\n",
    "        \n",
    "    clean = data[keepvars].set_index('date')\n",
    "    \n",
    "    return(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prep_ngram_data` optionally applies normalisation on word-counts to construct\n",
    "$$\n",
    "P_{w,t} = \\frac{N_{w,t}}{\\sum_{i}^I N_{i,t}}\n",
    "$$\n",
    "\n",
    "for word $w$ on day $t$, where the denominator is the word count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interactive plots \n",
    "(uses plotly - please submit an issue to github repo if the plots are 404 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactive(df,vars,header='Appearances in TKP archive'):\n",
    "    data = []\n",
    "    for v in vars:\n",
    "        data.append(go.Scatter(x = df.index,y = df[v],name=v))\n",
    "    \n",
    "    layout = dict(\n",
    "        title=header,\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1,label='1m',step='month',stepmode='backward'),\n",
    "                    dict(count=6,label='6m',step='month',stepmode='backward'),\n",
    "                    dict(count=1,label='YTD',step='year',stepmode='todate'),\n",
    "                    dict(count=1,label='1y',step='year',stepmode='backward'),\n",
    "                    dict(count=2,label='2y',step='year',stepmode='backward'),\n",
    "                    dict(step='all')\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(),\n",
    "            type='date'\n",
    "        )\n",
    "    )\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    return py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preliminaries\n",
    "working = '/media/alal/LAL_DATA/Newspapers/The Kathmandu Post'\n",
    "os.chdir(working)\n",
    "tmp = '/home/alal/tmp'\n",
    "inp = working + '/word_frequencies'\n",
    "\n",
    "# set up list for date ranges\n",
    "flist = date_stitcher('wfreqs_TKP_',2007, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disasters = ['earthquake', 'fire', 'flood','drought','landslide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 5.33 s, total: 1min 30s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stressors = prep_ngram_data(flist,disasters,inp,fuzzymatch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that daily word-counts don't bounce around too much over time - that would mean trends in raw counts are misleading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~apoorvalal/89.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_interactive(stressors,['wordcount'],header='word count TKP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~apoorvalal/91.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_interactive(stressors,disasters,header='Natural Disasters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
